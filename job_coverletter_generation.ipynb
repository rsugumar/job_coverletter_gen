{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef645663-d810-4574-aec5-a691c451fe48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported LlamaIndex\n",
      "Processing /Users/rsukumar/Downloads/Sukumar_RAGHAVAN_CV.pdf...\n",
      "[                                        ] (0/1)========================================[========================================] (1/1)]\n",
      "Processing /Users/rsukumar/Downloads/Sukumar_RAGHAVAN_CV.pdf...\n",
      "[                                        ] (0/1)========================================[========================================] (1/1)]\n"
     ]
    }
   ],
   "source": [
    "import pymupdf4llm\n",
    "\n",
    "my_cv_path = \"/Users/rsukumar/Downloads/Sukumar_RAGHAVAN_CV.pdf\"\n",
    "\n",
    "# Load pdf file\n",
    "llama_reader = pymupdf4llm.LlamaMarkdownReader()\n",
    "llama_docs = llama_reader.load_data(my_cv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "962f5df4-5173-423e-b8bc-848833e3744a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "import chromadb\n",
    "from chromadb.utils.embedding_functions import create_langchain_embedding\n",
    "from langchain_chroma import Chroma\n",
    "# from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from llama_index.core import StorageContext, VectorStoreIndex\n",
    "from llama_index.embeddings.langchain import LangchainEmbedding\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "\n",
    "# Using Huggingface embeddings\n",
    "# langchain_embeddings = HuggingFaceEmbeddings(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "\n",
    "# Using Ollama embeddings\n",
    "langchain_embeddings = OllamaEmbeddings(model=\"llama3.2\")\n",
    "ef = create_langchain_embedding(langchain_embeddings)\n",
    "embed_model = LangchainEmbedding(langchain_embeddings)\n",
    "\n",
    "# Keeping option to switch between Ephemeral / Persistent chroma client, if wanted\n",
    "chroma_db_persist_path = \"chroma-db-job-coverletter\"\n",
    "vector_db_collection_name = \"job-cv-vector-db-collection\"\n",
    "# ephemeral_chroma_client = chromadb.EphemeralClient()\n",
    "persistent_chroma_client = chromadb.PersistentClient(path=chroma_db_persist_path)\n",
    "vector_db_client = persistent_chroma_client\n",
    "\n",
    "chroma_collection = vector_db_client.get_or_create_collection(\n",
    "    vector_db_collection_name, embedding_function=ef\n",
    ")\n",
    "\n",
    "vector_store_from_client = Chroma(\n",
    "    client=vector_db_client,\n",
    "    collection_name=vector_db_collection_name,\n",
    "    embedding_function=ef,\n",
    ")\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    llama_docs,\n",
    "    storage_context=storage_context,\n",
    "    embed_model=embed_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b904603-063c-444a-9a4b-dd8b9fc6a3e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>The document appears to be a resume or CV for an individual named Sukumar Raghavan, highlighting his professional experience, skills, and education in the field of machine learning engineering.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm_instance = ChatOllama(model=\"llama3.2\", temperature=0)\n",
    "\n",
    "# Query Data\n",
    "query_engine = index.as_query_engine(llm=llm_instance, streaming=True)\n",
    "response = query_engine.query(\"What is the document all about?\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aaf7eb54-30aa-48b3-80e2-372c5bc70c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 2, updating n_results = 2\n",
      "Number of requested results 4 is greater than number of elements in index 2, updating n_results = 2\n",
      "Number of requested results 4 is greater than number of elements in index 2, updating n_results = 2\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>Dear Hiring Manager,\n",
       "\n",
       "I am writing to express my enthusiastic interest in the Machine Learning Engineer position at your esteemed organization. As a seasoned machine learning engineer with over 6 years of experience in AI, I am confident that my skills and expertise align perfectly with the requirements of this role.\n",
       "\n",
       "With a strong foundation in computer vision, NLP, CNN, LSTM, LLMs, vector databases, object detection, tracking, recommender systems, AutoML, model explainability, and distributed systems, I possess the technical expertise to develop cutting-edge AI solutions that address real-world problems. My experience with PyTorch, TensorFlow, Scikit-learn, Numpy, Pandas, Shap, XGBoost, OpenCV, Transformers, Langchain, LlamaIndex, ChromaDB, and other relevant technologies will enable me to make a significant impact in this role.\n",
       "\n",
       "As a seasoned machine learning engineer, I have led the development of ContagionNET, significantly enhancing COVID-19 detection through innovative use of computer vision and deep learning. My experience with SHAP, model explainability, and trust has allowed me to develop visual AI for image classification that enhances user understanding and visualization of model performance.\n",
       "\n",
       "I am particularly drawn to this role because of the opportunity to explore the potential of LLMs, Langchain, and vector databases to drive future innovation. I am eager to leverage my expertise in distributed systems, server architecture, and multithreading to develop scalable and efficient AI solutions that meet the organization's needs.\n",
       "\n",
       "In addition to my technical skills, I possess excellent communication and collaboration skills, which have been essential in leading distributed teams across the globe. My experience as a cofounder and senior software architect has also honed my ability to establish roadmaps, create prototypes, and demo products to investors.\n",
       "\n",
       "I am excited about the opportunity to join your team and contribute my expertise to develop cutting-edge AI solutions that drive business value. Thank you for considering my application. I look forward to discussing this opportunity further.\n",
       "\n",
       "Sincerely,\n",
       "Raghavan</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Use local Ollama model to generate the cover letter.\n",
    "from chromadb.utils.embedding_functions import create_langchain_embedding\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "# from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# Prompt template\n",
    "prompt_template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer just say \"I don't know\", don't try to make up an answer.\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer as a jobseeker:\"\"\"\n",
    "\n",
    "question = \"Write a cover letter for applying for the job role as described in the context matching the job description exactly in the additional context.\"\n",
    "llm = ChatOllama(model=\"llama3.2\", temperature=0)\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "chroma_db_persist_path = \"chroma-db-job-coverletter\"\n",
    "vector_db_collection_name = \"job-cv-vector-db-collection\"\n",
    "lc_embeddings = OllamaEmbeddings(model=\"llama3.2\")\n",
    "# lc_embeddings = HuggingFaceEmbeddings(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "ef2 = create_langchain_embedding(lc_embeddings)\n",
    "\n",
    "vector_db = Chroma(\n",
    "    collection_name=vector_db_collection_name,\n",
    "    persist_directory=chroma_db_persist_path,\n",
    "    embedding_function=ef2,\n",
    ")\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vector_db.as_retriever(),\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT},\n",
    "    chain_type=\"stuff\", # other techniques to experiment: \"map_reduce\", \"refine\", \"map_rerank\"\n",
    ")\n",
    "retrieved_docs = vector_db.similarity_search(\"professional summary\")\n",
    "retrieved_docs += vector_db.similarity_search(\"work experience\")\n",
    "retrieved_context = \"\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "\n",
    "add_job_description_context = \"\"\"\n",
    "\"\"\"\n",
    "\n",
    "context = f\"{retrieved_context}\\n\\nAdditional Context:\\n{add_job_description_context}\"\n",
    "\n",
    "result = qa_chain.invoke({\"query\": question, \"context\": context})\n",
    "\n",
    "display(Markdown(f\"<b>{result[\"result\"]}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f8a95a-de2c-4248-a9bf-803bb2846a60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "/Users/rsukumar/my_workspace/job_coverletter_gen",
   "language": "python",
   "name": "_users_rsukumar_my_workspace_job_coverletter_gen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
